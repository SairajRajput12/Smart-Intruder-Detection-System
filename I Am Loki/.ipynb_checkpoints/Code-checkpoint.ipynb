{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a701bcb-a6a2-49fb-a189-de1aea06b058",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49b5a38-0538-4a67-b26b-40e2328dc494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries succesfully imported\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "from collections import deque\n",
    "print(\"Libraries succesfully imported\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de52c7e-00df-44cc-a2cb-a0e5f6be754c",
   "metadata": {},
   "source": [
    "# Step 1: Code for using ip webcam application and capturing the video fottages from the phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d694ff-95ec-4b6d-a9fc-50b6fad71919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Window normal so we can resize it\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Note the starting time\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize these variables for calculating FPS\n",
    "fps = 0 \n",
    "frame_counter = 0\n",
    "\n",
    "# Read the video steram from the camera\n",
    "cap = cv2.VideoCapture('https://192.168.43.1:8080/video') # this url must be pasted from the ip webcam application.\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    \n",
    "    # Calculate the Average FPS\n",
    "    frame_counter += 1\n",
    "    fps = (frame_counter / (time.time() - start_time))\n",
    "    \n",
    "    # Display the FPS\n",
    "    cv2.putText(frame, 'FPS: {:.2f}'.format(fps), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255),1)\n",
    "    \n",
    "    # Show the Frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # Exit if q is pressed.\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release Capture and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96233618-45a9-41bb-884e-ccc35e556659",
   "metadata": {},
   "source": [
    "# Step 2: Twilio API For Messaging Purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4818af66-9ef7-4184-af00-0b60ef30b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client \n",
    "\n",
    "\n",
    "with open('credential.txt', 'r') as myfile:\n",
    "  data = myfile.read()\n",
    "\n",
    "# Convert data variable into dictionary\n",
    "info_dict = eval(data)\n",
    "\n",
    "# Your Account SID from twilio.com/console\n",
    "account_sid = info_dict['account_sid']\n",
    "\n",
    "# Your Auth Token from twilio.com/console\n",
    "auth_token  = info_dict['auth_token']\n",
    "\n",
    "# Set client and send the message\n",
    "client = Client(account_sid, auth_token)\n",
    "message = client.messages.create( to =info_dict['your_num'], from_ = info_dict['trial_num'], body= \"What's Up Man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534a6cf-6fc3-4cf7-a273-8c591d431d78",
   "metadata": {},
   "source": [
    "# Step 3: Building a Motion Detector with Background Subtraction and Contour detection:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e27b68-e1f4-46c1-b32f-74b7c4d695e8",
   "metadata": {},
   "source": [
    "## What are the background substraction methood ?? \n",
    "\n",
    "\n",
    "Basically these kinds of methods separate the background from the foreground in a video so for e.g. if a person walks in an empty room then the background subtraction algorithm would know thereâ€™s disturbance by subtracting the previously stored image of the room (without the person ) and the current image (with the person). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31d4bb-5115-41ef-afc2-5c46893bcefb",
   "metadata": {},
   "source": [
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Background Subtraction Parameters for `cv2.createBackgroundSubtractorMOG2()`\r\n",
    "\r\n",
    "The `cv2.createBackgroundSubtractorMOG2()` function in OpenCV is used to create a background subtractor object based on the MOG2 algorithm. This function takes three arguments:\r\n",
    "\r\n",
    "1. **detectShadows (Boolean)**:\r\n",
    "   - This parameter enables or disables shadow detection.\r\n",
    "   - When set to `True`, the algorithm detects shadows in the video.\r\n",
    "   - Shadow detection can provide smoother and more robust results, but it may slightly decrease processing speed.\r\n",
    "\r\n",
    "2. **history (Integer)**:\r\n",
    "   - The `history` parameter determines the number of previous frames used to create the background model.\r\n",
    "   - Increasing this value can be beneficial if the target object frequently stops or pauses in the video.\r\n",
    "\r\n",
    "3. **Threshold Limit (Integer)**:\r\n",
    "   - The threshold limit helps filter out noise present in the frame.\r\n",
    "   - Increasing this value can help remove noise, such as white spots in the frame.\r\n",
    "   - Additionally, morphological operations like erosion can further eliminate noise from the frame.\r\n",
    "\r\n",
    "These parameters are essential for fine-tuning the background subtraction process and improving the accuracy of object detection itebook for easy reference.**\n",
    "\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ef3d09-db0d-4da0-9718-af9e9166ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.BackgroundSubtractorMOG2 0000021F576324D0>\n"
     ]
    }
   ],
   "source": [
    "# For loading the video\n",
    "cap = cv2.VideoCapture('sample_video1.mp4') \n",
    "\n",
    "# Create the background subtractor object\n",
    "flog = cv2.createBackgroundSubtractorMOG2(detectShadows = True, varThreshold = 50, history = 2800)\n",
    "print(flog)\n",
    "\n",
    "while(True): \n",
    "    ret,frame = cap.read() \n",
    "\n",
    "    if not ret: \n",
    "        break\n",
    "\n",
    "     # Apply the background object on each frame\n",
    "    fgmask = flog.apply(frame) \n",
    "\n",
    "    # Get rid of the shadows\n",
    "    ret, fgmask = cv2.threshold(fgmask, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "     # Show the background subtraction frame.\n",
    "    cv2.imshow('All three',fgmask)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf06e5c-7d02-4821-b75e-aef2788c2443",
   "metadata": {},
   "source": [
    "# adding the dilation and erosion in this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec218486-15c5-45ee-96c5-6a0f0f71556e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
